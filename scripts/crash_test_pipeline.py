#!/usr/bin/env python3
"""
Crash Test COMPLET du Pipeline SerdaBot üöÄ

Simule de vrais viewers Twitch qui testent toutes les commandes.
Avec et sans LLM, pour valider le pipeline entier.

PHASES DE TEST:
1. Commandes !gameinfo normales (10 jeux populaires)
2. Test r√©silience typos (4 jeux avec fautes de frappe)
3. Commandes invalides (2 tests d'erreur)
4. Test cache (5 jeux d√©j√† en cache)
5. Messages de chat naturels (21 messages avec/sans commandes)
6. Test mod√®le LLM (8 interactions: !ask + mentions @serda_bot)

COUVERTURE COMPL√àTE:
‚úÖ Commandes !gameinfo (RAWG API + cache)
‚úÖ Messages de chat normaux (ignor√©s par le bot)
‚úÖ Commandes !ask (mod√®le LLM factuel)
‚úÖ Mentions @serda_bot (mod√®le LLM conversationnel)
‚úÖ Typo resilience (RAWG fuzzy search)
‚úÖ Gestion d'erreurs (commandes invalides)
‚úÖ Performance (cache vs API vs LLM)

R√âSULTATS ATTENDUS:
- ~88% de taux de succ√®s (commandes valides)
- 0.0ms (cache) √† 3s (API) pour !gameinfo
- 200ms √† 8s pour r√©ponses LLM (selon mod√®le)
- Messages normaux correctement ignor√©s
"""
import asyncio
import os
import sys
import time
from datetime import datetime

sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

# Activer le mode dev
os.environ["BOT_ENV"] = "dev"

from config.config import load_config
from core.cache import GAME_CACHE
from core.commands.ask_command import handle_ask_command
from core.commands.chill_command import handle_chill_command
from core.commands.game_command import handle_game_command


# Fake Message Twitch
class FakeAuthor:
    def __init__(self, name: str):
        self.name = name


class FakeChannel:
    def __init__(self):
        self.messages = []
    
    async def send(self, message: str):
        """Simule l'envoi d'un message."""
        self.messages.append(message)
        # Afficher avec couleur et timestamp
        timestamp = datetime.now().strftime("%H:%M:%S")
        print(f"[{timestamp}] ü§ñ BOT ‚Üí {message[:200]}...")


class FakeMessage:
    def __init__(self, author_name: str, content: str):
        self.author = FakeAuthor(author_name)
        self.content = content
        self.channel = FakeChannel()


# Sc√©narios de test
VIEWERS = [
    {"name": "GamerPro", "emoji": "üéÆ"},
    {"name": "CasualPlayer", "emoji": "üïπÔ∏è"},
    {"name": "StreamSniper", "emoji": "üéØ"},
    {"name": "ChatLurker", "emoji": "üëÄ"},
    {"name": "MemeLord", "emoji": "üòÇ"},
]

# Commandes √† tester (sans LLM d'abord)
GAME_COMMANDS = [
    "!gameinfo Hades",
    "!gameinfo Elden Ring",
    "!gameinfo Stardew Valley",
    "!gameinfo The Witcher 3",
    "!gameinfo Cyberpunk 2077",
    "!gameinfo JEUX_INEXISTANT_12345",
    "!gameinfo Baldur's Gate 3",
    "!gameinfo GTA V",
    "!gameinfo Minecraft",
    "!gameinfo Dark Souls 3",
]

# Commandes avec typos (test r√©silience RAWG)
TYPO_COMMANDS = [
    "!gameinfo Elden Rign",  # Elden Ring
    "!gameinfo Stardew Valey",  # Stardew Valley
    "!gameinfo Mincecraft",  # Minecraft
    "!gameinfo Baldurs Gate 3",  # Baldur's Gate 3
]

# Commandes invalides
INVALID_COMMANDS = [
    "!gameinfo",  # Sans argument
    "!gameinfo ",  # Argument vide
]

# Messages de chat naturels (conversation normale)
CHAT_MESSAGES = [
    # Messages sans commande (le bot ne devrait PAS r√©pondre)
    "Salut tout le monde ! üëã",
    "Quelqu'un joue √† Elden Ring ?",
    "@SerdaBot tu es l√† ?",
    "lol gg",
    "J'adore ce stream ! ‚ù§Ô∏è",
    "C'est quoi ce jeu ?",
    "@SerdaBot c'est quoi Hades ?",  # Mention mais pas de commande
    "Hades est trop bien",
    "Quelqu'un conna√Æt Celeste ?",
    "!help",  # Autre commande
    "PogChamp",
    "Le boss est trop dur !",
    "Tu joues bien ! üî•",
    "Quelle build tu utilises ?",
    "@SerdaBot tu peux me dire un truc sur Skyrim ?",  # Mention sans commande
    
    # Messages avec commandes valides m√©lang√©es
    "Oh ! !gameinfo Celeste",
    "@SerdaBot !gameinfo Hollow Knight",
    "J'ai entendu parler de Terraria, !gameinfo Terraria",
    "!gameinfo Undertale svp",
    "Yo !gameinfo Sekiro",
    "!gameinfo The Last of Us s'il te pla√Æt",
]

# Messages avec le mod√®le LLM (mention @serda_bot)
LLM_MESSAGES = [
    # Mentions directes du bot (d√©clenchent !chill)
    "@serda_bot salut, comment √ßa va ?",
    "@serda_bot tu connais Hades ?",
    "@serda_bot quel est ton jeu pr√©f√©r√© ?",
    "@serda_bot lol",
    "@serda_bot merci pour les infos !",
    
    # Commandes !ask (questions factuelles)
    "!ask C'est quoi Elden Ring ?",
    "!ask Qui a d√©velopp√© Stardew Valley ?",
    "!ask Quelle est la capitale de la France ?",
]


async def simulate_viewer_message(viewer: dict, command: str, config: dict, stats: dict):
    """
    Simule un viewer qui envoie une commande.
    
    Args:
        viewer: Dict avec name et emoji
        command: Commande √† tester
        config: Config du bot
        stats: Stats globales
    """
    # Cr√©er un fake message
    message = FakeMessage(viewer["name"], command)
    
    # Afficher le viewer qui parle
    timestamp = datetime.now().strftime("%H:%M:%S")
    print(f"\n{'='*80}")
    print(f"[{timestamp}] {viewer['emoji']} {viewer['name']}: {command}")
    print(f"{'='*80}")
    
    stats['total_commands'] += 1
    
    try:
        # V√©rifier si c'est une commande !gameinfo
        if "!gameinfo " in command:
            # Extraire le nom du jeu (apr√®s !gameinfo)
            game_start = command.find("!gameinfo ") + 10
            game_name = command[game_start:].strip()
            
            if not game_name:
                stats['invalid_commands'] += 1
                print("‚ùå Commande invalide (pas de jeu)")
                return
            
            # Mesurer le temps
            start = time.time()
            
            # Appeler le handler (comme le vrai bot)
            await handle_game_command(
                message=message,
                config=config,
                game_name=game_name,
                now=time.time()
            )
            
            duration = time.time() - start
            
            # V√©rifier la r√©ponse
            if message.channel.messages:
                response = message.channel.messages[-1]
                
                if "‚ùå" in response or "introuvable" in response.lower():
                    stats['not_found'] += 1
                    stats['response_times'].append(duration)
                else:
                    stats['success'] += 1
                    stats['response_times'].append(duration)
                    
                    # V√©rifier si le cache a √©t√© utilis√©
                    if "‚ö°" in response or duration < 0.1:
                        stats['cache_hits'] += 1
            else:
                stats['no_response'] += 1
        
        else:
            # Message de chat normal (pas une commande !gameinfo)
            stats['chat_messages'] += 1
            print("üí¨ Message de chat (ignor√© par le handler)")
    
    except Exception as e:
        stats['errors'] += 1
        print(f"‚ùå ERREUR: {e}")
        import traceback
        traceback.print_exc()


async def simulate_chat_message(viewer: dict, message_text: str, stats: dict):
    """
    Simule un message de chat normal (pas forc√©ment une commande).
    
    Args:
        viewer: Dict avec name et emoji
        message_text: Texte du message
        stats: Stats globales
    """
    timestamp = datetime.now().strftime("%H:%M:%S")
    print(f"\n[{timestamp}] {viewer['emoji']} {viewer['name']}: {message_text}")
    
    # V√©rifier si c'est une commande !gameinfo
    if "!gameinfo " in message_text:
        stats['chat_with_commands'] += 1
        print("   ‚Üí üéÆ Contient une commande !gameinfo (sera trait√©e)")
    elif "!ask " in message_text:
        stats['chat_with_commands'] += 1
        print("   ‚Üí üß† Contient une commande !ask (sera trait√©e)")
    elif "@serda_bot" in message_text.lower():
        stats['chat_with_commands'] += 1
        print("   ‚Üí ü§ñ Mention du bot (d√©clenchera !chill)")
    else:
        stats['normal_chat'] += 1
        print("   ‚Üí üí¨ Message normal (bot ne r√©pond pas)")


async def simulate_llm_message(viewer: dict, message_text: str, config: dict, stats: dict):
    """
    Simule un message qui d√©clenche le LLM (!ask ou mention du bot).
    
    Args:
        viewer: Dict avec name et emoji
        message_text: Texte du message
        config: Config du bot
        stats: Stats globales
    """
    message = FakeMessage(viewer["name"], message_text)
    
    timestamp = datetime.now().strftime("%H:%M:%S")
    print(f"\n{'='*80}")
    print(f"[{timestamp}] {viewer['emoji']} {viewer['name']}: {message_text}")
    print(f"{'='*80}")
    
    stats['llm_commands'] += 1
    
    try:
        if "!ask " in message_text:
            # Extraire la question
            question = message_text.split("!ask ", 1)[1].strip()
            
            if not question:
                stats['invalid_commands'] += 1
                print("‚ùå Commande !ask invalide (pas de question)")
                return
            
            # Mesurer le temps
            start = time.time()
            
            # Appeler le handler !ask
            await handle_ask_command(
                message=message,
                config=config,
                question=question,
                now=time.time()
            )
            
            duration = time.time() - start
            
            # V√©rifier la r√©ponse
            if message.channel.messages:
                stats['llm_success'] += 1
                stats['llm_response_times'].append(duration)
                print(f"‚úÖ R√©ponse LLM !ask en {duration*1000:.1f}ms")
            else:
                stats['llm_no_response'] += 1
        
        elif "@serda_bot" in message_text.lower():
            # Mesurer le temps
            start = time.time()
            
            # Appeler le handler !chill
            await handle_chill_command(
                message=message,
                config=config,
                now=time.time()
            )
            
            duration = time.time() - start
            
            # V√©rifier la r√©ponse
            if message.channel.messages:
                stats['llm_success'] += 1
                stats['llm_response_times'].append(duration)
                print(f"‚úÖ R√©ponse LLM !chill en {duration*1000:.1f}ms")
            else:
                stats['llm_no_response'] += 1
        
        else:
            stats['llm_no_response'] += 1
            print("‚ö†Ô∏è Message LLM non reconnu")
    
    except Exception as e:
        stats['llm_errors'] += 1
        print(f"‚ùå ERREUR LLM: {e}")
        import traceback
        traceback.print_exc()


async def run_crash_test():
    """Lance le crash test complet."""
    print("\n" + "="*80)
    print("üöÄ CRASH TEST COMPLET DU PIPELINE SERDABOT")
    print("="*80)
    
    config = load_config()
    
    # Stats du cache avant
    cache_stats_before = GAME_CACHE.stats()
    print(f"\nüì¶ Cache avant: {cache_stats_before['valid_entries']} entr√©es")
    
    # Stats globales
    stats = {
        'total_commands': 0,
        'success': 0,
        'not_found': 0,
        'invalid_commands': 0,
        'no_response': 0,
        'errors': 0,
        'cache_hits': 0,
        'response_times': [],
        'chat_messages': 0,
        'normal_chat': 0,
        'chat_with_commands': 0,
        'llm_commands': 0,
        'llm_success': 0,
        'llm_no_response': 0,
        'llm_errors': 0,
        'llm_response_times': [],
    }
    
    # Phase 1: Commandes normales
    print("\n" + "="*80)
    print("üìã PHASE 1: Commandes !gameinfo normales")
    print("="*80)
    
    for i, command in enumerate(GAME_COMMANDS):
        viewer = VIEWERS[i % len(VIEWERS)]
        await simulate_viewer_message(viewer, command, config, stats)
        await asyncio.sleep(0.2)  # Petit d√©lai entre messages
    
    # Phase 2: Commandes avec typos
    print("\n" + "="*80)
    print("üìã PHASE 2: Test r√©silience (typos)")
    print("="*80)
    
    for i, command in enumerate(TYPO_COMMANDS):
        viewer = VIEWERS[i % len(VIEWERS)]
        await simulate_viewer_message(viewer, command, config, stats)
        await asyncio.sleep(0.2)
    
    # Phase 3: Commandes invalides
    print("\n" + "="*80)
    print("üìã PHASE 3: Commandes invalides")
    print("="*80)
    
    for i, command in enumerate(INVALID_COMMANDS):
        viewer = VIEWERS[i % len(VIEWERS)]
        await simulate_viewer_message(viewer, command, config, stats)
        await asyncio.sleep(0.2)
    
    # Phase 4: Test cache (re-test des m√™mes jeux)
    print("\n" + "="*80)
    print("üìã PHASE 4: Test du cache (m√™me jeux)")
    print("="*80)
    
    cache_test_commands = GAME_COMMANDS[:5]  # 5 premiers
    for i, command in enumerate(cache_test_commands):
        viewer = VIEWERS[i % len(VIEWERS)]
        await simulate_viewer_message(viewer, command, config, stats)
        await asyncio.sleep(0.1)  # Plus rapide car cache
    
    # Phase 5: Messages de chat naturels
    print("\n" + "="*80)
    print("üìã PHASE 5: Messages de chat naturels (avec/sans commandes)")
    print("="*80)
    print("üí° Simule un vrai chat Twitch avec des messages normaux")
    
    for i, chat_msg in enumerate(CHAT_MESSAGES):
        viewer = VIEWERS[i % len(VIEWERS)]
        
        # Si le message contient !gameinfo, utiliser le handler complet
        if "!gameinfo " in chat_msg:
            await simulate_viewer_message(viewer, chat_msg, config, stats)
        else:
            # Sinon juste afficher le message (le bot ne r√©pond pas)
            await simulate_chat_message(viewer, chat_msg, stats)
        
        await asyncio.sleep(0.3)  # D√©lai r√©aliste entre messages
    
    # Phase 6: Test du mod√®le LLM (!ask + mention @serda_bot)
    print("\n" + "="*80)
    print("üìã PHASE 6: Test du mod√®le LLM (!ask + mention @serda_bot)")
    print("="*80)
    print("üß† Simule des interactions avec le mod√®le IA")
    print("‚ö†Ô∏è ATTENTION: Cette phase peut √™tre longue selon le mod√®le")
    
    for i, llm_msg in enumerate(LLM_MESSAGES):
        viewer = VIEWERS[i % len(VIEWERS)]
        await simulate_llm_message(viewer, llm_msg, config, stats)
        await asyncio.sleep(0.5)  # D√©lai pour le mod√®le


    
    # R√©sultats finaux
    print("\n" + "="*80)
    print("üìä R√âSULTATS DU CRASH TEST")
    print("="*80)
    
    cache_stats_after = GAME_CACHE.stats()
    
    print(f"\nüéØ Commandes:")
    print(f"   Total:     {stats['total_commands']}")
    print(f"   ‚úÖ Succ√®s:  {stats['success']}")
    print(f"   ‚ùå Non trouv√©: {stats['not_found']}")
    print(f"   ‚ö†Ô∏è Invalides: {stats['invalid_commands']}")
    print(f"   üîá Sans r√©ponse: {stats['no_response']}")
    print(f"   üí• Erreurs: {stats['errors']}")
    
    print(f"\nüí¨ Chat:")
    print(f"   Messages normaux: {stats['normal_chat']}")
    print(f"   Avec commandes:   {stats['chat_with_commands']}")
    print(f"   Total messages:   {stats['normal_chat'] + stats['chat_with_commands']}")
    
    # Ratio messages/commandes
    total_messages = stats['normal_chat'] + stats['chat_with_commands']
    if total_messages > 0:
        command_ratio = (stats['chat_with_commands'] / total_messages) * 100
        print(f"   Ratio commandes:  {command_ratio:.1f}% des messages")
    
    # Comportement du bot
    print(f"\nü§ñ Comportement du bot:")
    print(f"   R√©ponses donn√©es:     {stats['success'] + stats['not_found']}")
    print(f"   Messages ignor√©s:     {stats['normal_chat']}")
    print(f"   (Le bot ne r√©pond qu'aux !gameinfo)")
    
    # Stats LLM
    if stats['llm_commands'] > 0:
        print(f"\nüß† Mod√®le LLM (!ask + @serda_bot):")
        print(f"   Total appels:     {stats['llm_commands']}")
        print(f"   ‚úÖ Succ√®s:        {stats['llm_success']}")
        print(f"   üîá Sans r√©ponse:  {stats['llm_no_response']}")
        print(f"   üí• Erreurs:       {stats['llm_errors']}")
        
        if stats['llm_response_times']:
            avg_llm_time = sum(stats['llm_response_times']) / len(stats['llm_response_times'])
            min_llm_time = min(stats['llm_response_times'])
            max_llm_time = max(stats['llm_response_times'])
            
            print(f"\n   ‚è±Ô∏è Performance LLM:")
            print(f"      Temps moyen: {avg_llm_time*1000:.1f}ms")
            print(f"      Plus rapide: {min_llm_time*1000:.1f}ms")
            print(f"      Plus lent:   {max_llm_time*1000:.1f}ms")



    
    if stats['response_times']:
        avg_time = sum(stats['response_times']) / len(stats['response_times'])
        min_time = min(stats['response_times'])
        max_time = max(stats['response_times'])
        
        print(f"\n‚è±Ô∏è Performance:")
        print(f"   Temps moyen: {avg_time*1000:.1f}ms")
        print(f"   Plus rapide: {min_time*1000:.1f}ms")
        print(f"   Plus lent:   {max_time*1000:.1f}ms")
    
    print(f"\nüíæ Cache:")
    print(f"   Avant:       {cache_stats_before['valid_entries']} entr√©es")
    print(f"   Apr√®s:       {cache_stats_after['valid_entries']} entr√©es")
    print(f"   Nouvelles:   {cache_stats_after['valid_entries'] - cache_stats_before['valid_entries']}")
    print(f"   Hits estim√©s: {stats['cache_hits']}")
    
    if cache_stats_after['cache_file']:
        if os.path.exists(cache_stats_after['cache_file']):
            size = os.path.getsize(cache_stats_after['cache_file'])
            print(f"   Fichier:     {cache_stats_after['cache_file']} ({size/1024:.1f} KB)")
    
    # Taux de succ√®s
    if stats['total_commands'] > 0:
        success_rate = (stats['success'] / stats['total_commands']) * 100
        print(f"\nüéâ Taux de succ√®s: {success_rate:.1f}%")
    
    print(f"\n{'='*80}")
    print("‚úÖ CRASH TEST TERMIN√â !")
    print("="*80)
    print()


async def main():
    """Point d'entr√©e."""
    print("\nüß™ Crash Test Pipeline SerdaBot")
    print("="*80)
    print("\nüìã 6 PHASES DE TEST:")
    print("   1Ô∏è‚É£  Commandes !gameinfo normales (10 jeux)")
    print("   2Ô∏è‚É£  R√©silience typos (4 jeux avec fautes)")
    print("   3Ô∏è‚É£  Commandes invalides (2 tests)")
    print("   4Ô∏è‚É£  Cache performance (5 jeux)")
    print("   5Ô∏è‚É£  Messages chat naturels (21 messages)")
    print("   6Ô∏è‚É£  Mod√®le LLM (!ask + @serda_bot, 8 interactions)")
    print("\nüéÆ Simule de vrais viewers qui testent les commandes")
    print("‚ö° Tests avec et sans cache")
    print("ü§ñ Tests avec mod√®le IA (LM Studio / OpenAI)")
    print("üîç Validation du pipeline complet")
    
    choice = input("\nLancer le crash test ? (Y/n): ").strip().lower()
    
    if choice in ['', 'y', 'yes', 'oui', 'o']:
        print("\nüöÄ Lancement du crash test...\n")
        await run_crash_test()
    else:
        print("\n‚ùå Test annul√©")


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è Crash test interrompu")
