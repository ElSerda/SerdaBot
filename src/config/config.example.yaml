# ===== SERDABOT CONFIGURATION EXAMPLE =====
# 
# üìå INSTRUCTIONS :
# 1. Cr√©er le dossier local : mkdir -p ../SerdaBot-local/config
# 2. Copier ce fichier : cp src/config/config.example.yaml ../SerdaBot-local/config/config.yaml
# 3. Remplir les vraies valeurs (tokens, cl√©s API, etc.)
# 4. Lancer le bot : ./start_bot.sh (d√©tecte automatiquement la config locale)
#
# ‚ö†Ô∏è  NE JAMAIS COMMITER config.yaml avec de vraies cl√©s !

bot:
  language: "fr"                            # Langue par d√©faut ("en" ou "fr")
  name: "your_bot_name"                     # Nom du bot Twitch (ex: my_awesome_bot)
  channel: "your_channel_name"              # Nom du channel Twitch (sans @)
  model_path: "src/model"                   # Chemin du dossier du mod√®le local
  model_file: "your-model.gguf"             # Nom du fichier GGUF du mod√®le
  model_type: "openai"                      # Type de mod√®le ("mistral", "llama", "openai", etc.)
  openai_model: "gpt-3.5-turbo"             # Mod√®le OpenAI √† utiliser
  use_gpu: true                             # Activer l'acc√©l√©ration GPU (true/false)
  gpu_layers: 50                            # Nombre de layers GPU
  cooldown: 10                              # Cooldown entre r√©ponses (en secondes)
  model_endpoint: http://127.0.0.1:1234/v1/chat/completions  # Endpoint LM Studio
  api_url: http://127.0.0.1:1234/v1/chat/completions         # API LM Studio
  model_name: "qwen2.5-3b-instruct"         # Nom du mod√®le (Qwen2.5-3B-Instruct-Q4_K_M recommand√©)
  model_timeout: 10                         # Timeout requ√™tes mod√®le (secondes)
  max_tokens_ask: 120                       # Max tokens mode ASK (r√©ponses d√©taill√©es)
  max_tokens_chill: 60                      # Max tokens mode CHILL (conversations)
  temperature_ask: 0.4                      # Temperature ASK (factuel)
  temperature_chill: 0.7                    # Temperature CHILL (cr√©atif)
  log_ia: true                              # Activer logs IA (debug)
  debug: true                               # Verbose output (debug)
  translation: libretranslate               # Service de traduction ("model" ou "libretranslate")
  reset_cache_on_boot: false                # Reset cache au d√©marrage (default: false)
  kofi_url: "https://ko-fi.com/your_username"       # URL Ko-fi pour donations
  donation_message: "‚òï Merci pour le support ! Tu peux soutenir [YourName] ici : {kofi_url} üíú"
  connect_message: "C'est ici les pr√©coces ? ‚òï"    # Message de connexion (vide = d√©sactiv√©)

  enabled_commands:
    - game
    - chill
    - ask
    - trad

openai:
  api_key: "sk-proj-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"  # Cl√© API OpenAI (depuis platform.openai.com)

twitch:
  token: "oauth:XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"   # Token OAuth Twitch (depuis twitchtokengenerator.com)
  client_id: "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"     # Client ID Twitch (dev.twitch.tv)
  client_secret: "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX" # Client Secret Twitch
  bot_id: "123456789"                                # User ID du bot Twitch

igdb:
  client_id: "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"     # Client ID IGDB (dev.twitch.tv)
  client_secret: "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX" # Client Secret IGDB

rawg:
  api_key: "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"       # Cl√© API RAWG (rawg.io/apidocs)
