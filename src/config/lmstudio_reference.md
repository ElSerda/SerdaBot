# üéõÔ∏è LM Studio - Configuration de R√©f√©rence

Ce fichier documente les **param√®tres optimaux** pour LM Studio avec SerdaBot.

---

## üìã Param√®tres recommand√©s

### **Model Settings** (onglet "Model" dans LM Studio)

```yaml
Temperature:         0.7
Top P:               0.9
Top K:               40-100 (si disponible)
Max Tokens:          60
Presence Penalty:    0.6
Frequency Penalty:   0.4
Stop Sequences:      ["\n", "User:", "Assistant:", "@"]
```

---

## üéØ Explication des param√®tres

### **Temperature (0.7)**
- Contr√¥le la cr√©ativit√© du mod√®le
- `0.3` = Tr√®s pr√©visible, r√©p√©titif
- `0.7` = **√âquilibr√©** (recommand√© pour Twitch)
- `1.0+` = Trop al√©atoire, incoh√©rent

### **Top P (0.9)**
- S√©lectionne les 90% meilleurs tokens
- √âvite les choix trop improbables
- Garde une bonne diversit√©

### **Top K (40-100)**
- Limite aux K meilleurs tokens
- Compl√©mentaire √† Top P
- R√©duit encore plus l'al√©atoire

### **Max Tokens (60)**
- Limite la longueur des r√©ponses
- **60 tokens ‚âà 12-25 mots** (parfait pour Twitch)
- R√©duit la latence sur machines lentes

### **Presence Penalty (0.6)**
- P√©nalise la **r√©p√©tition d'id√©es**
- √âvite : "Je suis gentil. Je suis toujours gentil."
- Force le mod√®le √† varier ses concepts

### **Frequency Penalty (0.4)**
- P√©nalise la **r√©p√©tition de mots**
- √âvite : "incroyable incroyable incroyable"
- Rend les r√©ponses plus naturelles

### **Stop Sequences**
- `\n` : Coupe √† la premi√®re ligne (1 phrase max)
- `User:` / `Assistant:` : √âvite que le mod√®le simule un dialogue
- `@` : √âvite les mentions intempestives

---

## üöÄ Performance attendue

### **Machine moderne** (GTX 1660+ / RTX)
- Vitesse : **50-100 tok/s**
- Latence : **~1-2 secondes**
- Qualit√© : Excellente

### **Machine ancienne** (GTX 780 / CPU)
- Vitesse : **3-10 tok/s**
- Latence : **~3-5 secondes**
- Qualit√© : Tr√®s bonne (sous timeout 10s)

---

## üìù System Prompt utilis√© par le bot

```
Bot Twitch FR. R√©ponds en UNE phrase max (12-25 mots).
Ton fun et complice. Pas d'auto-flatterie. 0-2 √©mojis max.
Pas de listes, pas de !!!, pas de citations longues.
```

---

## üîß Configuration dans LM Studio

1. **Lancer LM Studio**
2. Aller dans **Developer** ‚Üí **Server**
3. D√©marrer le serveur sur `http://localhost:1234/v1`
4. Charger un mod√®le (ex: Qwen 2.5 1.5B Instruct)
5. Appliquer les param√®tres ci-dessus dans l'interface
6. Le bot se connectera automatiquement !

---

## üéÆ Mod√®les recommand√©s

### **Petit & Rapide** (1-3B params)
- ‚úÖ **Qwen 2.5 1.5B Instruct** (recommand√©)
- ‚úÖ Phi-3 Mini (3.8B)
- Bon pour : Machines lentes, latence minimale

### **Moyen** (7-8B params)
- ‚úÖ Qwen 2.5 7B Instruct
- ‚úÖ Llama 3.2 8B
- Bon pour : RTX 3060+, meilleure qualit√©

### **Gros** (14B+ params)
- Qwen 2.5 14B Instruct
- Llama 3.1 15B
- Bon pour : RTX 4070+, qualit√© maximale

---

## üí° Tips

- **CPU uniquement** : Utilisez un mod√®le ‚â§3B (Qwen 2.5 1.5B)
- **GPU <8GB VRAM** : Mod√®le ‚â§7B
- **GPU ‚â•12GB VRAM** : Mod√®le 14B+ possible
- **Twitch = latence critique** : Privil√©giez la vitesse sur la taille

---

## üÜò D√©pannage

### Le bot timeout (>10s)
- ‚ö†Ô∏è Mod√®le trop gros pour ta machine
- Solution : Passer √† un mod√®le plus petit (1.5B)

### R√©ponses trop courtes/vides
- ‚ö†Ô∏è `max_tokens` trop bas
- Solution : Augmenter √† 100 (mais latence +)

### R√©ponses g√©n√©riques ("ma liste de qualit√©s...")
- ‚úÖ Le garde-fou lexical filtre √ßa automatiquement !
- Le bot r√©essaiera avec un meilleur prompt

---

üìÖ **Derni√®re mise √† jour** : Optimisations Twitch (Oct 2025)
