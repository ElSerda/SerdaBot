# üéõÔ∏è LM Studio - Configuration de R√©f√©rence

Ce fichier documente les **param√®tres optimaux** pour LM Studio avec SerdaBot.

---

## üéØ TL;DR : Un seul preset suffit !

**LM Studio ne permet qu'un seul profil de param√®tres √† la fois.**  
‚Üí Configure avec le preset **"Standard Twitch"** ci-dessous.  
‚Üí Les variations de comportement (chill/hype) sont g√©r√©es **dans les prompts syst√®me**, pas dans LM Studio.

---

## ‚öôÔ∏è Preset "Standard Twitch" (UNIQUE)

**√Ä configurer dans LM Studio :**

```yaml
Temperature:         0.7
Top-K:               40
Top-P:               0.9
Min-P:               0.05
Repeat Penalty:      1.10
Max Tokens:          50
Limit response:      ON
Stop Sequences:      ["\n", "User:", "Assistant:", "@"]
```

**Ce preset fonctionne pour toutes les commandes** (`!chill`, `!ask`, `!game`) car :
- Les prompts syst√®me sont **ultra-stricts** : "UNE phrase (12-25 mots MAX)"
- Le code ajuste les param√®tres si besoin (ex: `max_tokens` peut varier par commande)
- Pas besoin de changer la config LM Studio selon la commande

---

## üéØ Explication des param√®tres

### **Temperature (0.7)**
- Contr√¥le la cr√©ativit√© du mod√®le
- `0.6` = Plus safe, moins d'impro (Chill/Hello)
- `0.7` = **√âquilibr√©** (recommand√© par d√©faut)
- `0.8` = Plus fun, plus piquant (Hype mode)

### **Top-K (40)**
- Limite aux 40 meilleurs tokens
- Coupe les choix improbables
- Montez √† 60 pour mode Hype

### **Top-P (0.9)**
- S√©lectionne les 90% meilleurs tokens (cumul de probabilit√©)
- Compl√©mentaire √† Top-K
- `0.85` = Plus strict, `0.92` = Plus vari√©

### **Min-P (0.05)**
- Coupe les "queues bizarres" de probabilit√©
- Laisse TOUJOURS activ√© !
- √âvite les tokens vraiment improbables

### **Repeat Penalty (1.10)**
- P√©nalise la r√©p√©tition de tokens
- `1.10` = √âquilibr√©
- `1.15` = Si le bot radote trop
- `1.05` = Mode Hype (peut r√©p√©ter pour emphase)

### **Max Tokens (50)**
- **50 tokens ‚âà 12-25 mots** (parfait pour Twitch one-liner)
- R√©duit la latence sur GTX 780
- Plus fiable que "Limit response length" seul

### **Stop Sequences**
- `\n` : Coupe √† la premi√®re ligne (garantit 1 phrase)
- `User:` / `Assistant:` : √âvite que le mod√®le simule un dialogue
- `@` : √âvite les mentions intempestives

---

## üöÄ Performance attendue

### **Machine moderne** (GTX 1660+ / RTX)
- Vitesse : **50-100 tok/s**
- Latence : **~1-2 secondes**
- Qualit√© : Excellente

### **Machine ancienne** (GTX 780 / CPU)
- Vitesse : **3-10 tok/s**
- Latence : **~3-5 secondes**
- Qualit√© : Tr√®s bonne (sous timeout 10s)

---

## üìù System Prompt utilis√© par le bot

```
Bot Twitch FR, UNE phrase (12-25 mots), ton fun/complice,
pas de /me, 0-2 √©mojis, pas d'auto-flatterie.
```

**Pourquoi ce format strict ?**
- ‚úÖ Force des r√©ponses courtes (Twitch = latence critique)
- ‚úÖ √âvite les pav√©s et les listes
- ‚úÖ Bloque l'auto-congratulation ("ma liste de qualit√©s incroyables...")
- ‚úÖ Ton l√©ger et fun, pas corporate

---

## üîß Configuration dans LM Studio

1. **Lancer LM Studio**
2. Aller dans **Developer** ‚Üí **Server**
3. D√©marrer le serveur sur `http://localhost:1234/v1`
4. Charger un mod√®le (ex: Qwen 2.5 1.5B Instruct)
5. Appliquer les param√®tres ci-dessus dans l'interface
6. Le bot se connectera automatiquement !

---

## üéÆ Mod√®les recommand√©s

### **Petit & Rapide** (1-3B params)
- ‚úÖ **Qwen 2.5 1.5B Instruct** (recommand√©)
- ‚úÖ Phi-3 Mini (3.8B)
- Bon pour : Machines lentes, latence minimale

### **Moyen** (7-8B params)
- ‚úÖ Qwen 2.5 7B Instruct
- ‚úÖ Llama 3.2 8B
- Bon pour : RTX 3060+, meilleure qualit√©

### **Gros** (14B+ params)
- Qwen 2.5 14B Instruct
- Llama 3.1 15B
- Bon pour : RTX 4070+, qualit√© maximale

---

## üí° Tips

- **CPU uniquement** : Utilisez un mod√®le ‚â§3B (Qwen 2.5 1.5B)
- **GPU <8GB VRAM** : Mod√®le ‚â§7B
- **GPU ‚â•12GB VRAM** : Mod√®le 14B+ possible
- **Twitch = latence critique** : Privil√©giez la vitesse sur la taille

---

## üÜò D√©pannage

### Le bot timeout (>10s)
- ‚ö†Ô∏è Mod√®le trop gros pour ta machine
- Solution : Passer √† un mod√®le plus petit (1.5B)

### R√©ponses trop courtes/vides
- ‚ö†Ô∏è `max_tokens` trop bas
- Solution : Augmenter √† 100 (mais latence +)

### R√©ponses g√©n√©riques ("ma liste de qualit√©s...")
- ‚úÖ Le garde-fou lexical filtre √ßa automatiquement !
- Le bot r√©essaiera avec un meilleur prompt

---

üìÖ **Derni√®re mise √† jour** : Optimisations Twitch (Oct 2025)
