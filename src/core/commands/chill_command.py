"""Commande !chill - Mode conversationnel"""

import asyncio
import re
import time

from twitchio import Message  # pyright: ignore[reportPrivateImportUsage]

from prompts.prompt_loader import make_prompt
from src.core.fallbacks import get_fallback_response
from utils.model_utils import call_model


def detect_and_translate_artifacts(response: str, translator, debug: bool = False) -> tuple[str, bool, str, str]:
    """
    D√©tecte les caract√®res chinois dans la r√©ponse et ajoute leur traduction entre parenth√®ses.
    
    Exemple: "C'est uneÁôæÁßëÂÖ®‰π¶!" ‚Üí "C'est uneÁôæÁßëÂÖ®‰π¶ (encyclop√©die)!"
    
    Args:
        response: R√©ponse du LLM
        translator: Instance du Translator pour la traduction
        debug: Mode debug pour logs
    
    Returns:
        Tuple (response_filtr√©e, has_artifact, premier_mot_chinois, traduction)
    """
    # Pattern pour d√©tecter les caract√®res chinois
    chinese_pattern = r'([\u4e00-\u9fff]+)'
    
    # Variables pour tracker le premier artefact
    first_chinese = None
    first_translation = None
    has_artifact = False
    
    # Fonction de remplacement appel√©e pour chaque match
    def add_translation(match):
        nonlocal first_chinese, first_translation, has_artifact
        chinese_word = match.group(1)
        translation = translator.translate_chinese(chinese_word)
        
        # Capturer le premier artefact pour la f√©licitation
        if not has_artifact:
            first_chinese = chinese_word
            first_translation = translation
            has_artifact = True
        
        if debug:
            print(f"[ARTIFACT] üÄÑ D√©tect√©: '{chinese_word}' ‚Üí '{translation}'")
        
        # Injecter la traduction juste apr√®s le mot chinois
        return f"{chinese_word} ({translation})"
    
    # Remplacer chaque occurrence de caract√®res chinois
    filtered_response = re.sub(chinese_pattern, add_translation, response)
    
    # Log si des artefacts ont √©t√© d√©tect√©s
    if has_artifact and debug:
        print(f"[ARTIFACT] ‚úÖ Filtre appliqu√©: {response[:50]}... ‚Üí {filtered_response[:50]}...")
        print(f"[ARTIFACT] üéì Easter egg d√©tect√©: '{first_chinese}' = '{first_translation}'")
    
    return filtered_response, has_artifact, first_chinese or "", first_translation or ""


def detect_vague_game_response(user_msg: str, response: str) -> str | None:
    """D√©tecte si le bot parle d'un jeu de fa√ßon dangereuse (vague OU avec dates).
    
    Philosophie KISS : Le LLM ne doit JAMAIS citer une ann√©e dans un contexte jeu.
    C'est IGDB qui parle des dates, pas le LLM.
    
    Args:
        user_msg: Message original de l'utilisateur
        response: R√©ponse g√©n√©r√©e par le mod√®le
        
    Returns:
        Message de redirection si d√©tection, None sinon
    """
    game_keywords = [
        # Mots g√©n√©riques contextuels (pas de noms de jeux)
        "jeu", "game", "sorti", "sortie", "sortit", "sortira", "sort", "quand", "date", 
        "plateforme", "pc", "ps5", "ps4", "ps3", "xbox", "switch", 
        "steam", "mobile", "console", "dispo", "disponible",
        # Noms de franchises courantes (pour attraper "Quand sort Zelda ?")
        "zelda", "mario", "pokemon", "pok√©mon", "gta", "elden", "skyrim", 
        "cyberpunk", "witcher", "god of war", "horizon", "final fantasy"
    ]
    
    vague_words = [
        "je crois", "peut-√™tre", "il parait", "annonc√©", 
        "je cherche", "non", "pas de", "peut-√™tre une",
        "keepers 2", "serda, je cherche", "je ne sais pas",
        "sera", "serait", "pourrait", "devrait", "va", "irait",  # Futur/conditionnel = souvent invention
        "bientot", "biento", "bient√¥t", "prochainement"  # Argot courant = √©vasion
    ]
    
    user_lower = user_msg.lower()
    response_lower = response.lower()
    
    # D√©tection contexte jeu : keywords obligatoires
    has_game = any(kw in user_lower for kw in game_keywords)
    
    # Pas de contexte jeu ‚Üí pas de filtre
    if not has_game:
        return None
    
    # D√©tection 1 : Mots vagues
    is_vague = any(vw in response_lower for vw in vague_words)
    
    # D√©tection 2 : TOUTE ann√©e (1000-2999) - Pattern intemporel
    # Le LLM ne doit JAMAIS dater un jeu, peu importe l'ann√©e
    year_pattern = re.compile(r'\b(1[0-9]{3}|2[0-9]{3})\b')
    has_year = year_pattern.search(response)
    
    # Si user parle de jeu ET (bot vague OU bot cite une ann√©e)
    if is_vague or has_year:
        # Extraire le nom du jeu du message user
        game_hint = ""
        
        # Termes g√©n√©riques √† exclure (pas des noms de jeux)
        GENERIC_TERMS = {"aaa", "jeu", "game", "titre", "truc", "machin", "prochain", "nouveau", "dernier"}
        
        # Chercher noms propres (majuscules) dans le message
        words = user_msg.split()
        game_words = []
        
        for word in words:
            word_clean = word.strip(",.!?")
            word_lower = word_clean.lower()
            
            # Filtrage : exclure termes g√©n√©riques ou trop courts
            if word_lower in GENERIC_TERMS or len(word_clean) < 3:
                continue
            
            # Nom propre = majuscule ET pas mot interrogatif/commun
            if (word_clean and word_clean[0].isupper() 
                and word_lower not in ["date", "quand", "pour", "dans", "avec", "sans", "quel", "quelle"]):
                game_words.append(word_lower)
            elif game_words:
                # Si on avait commenc√© √† collecter et qu'on rencontre un mot non-propre, stop
                break
        
        if game_words:
            game_hint = f" {' '.join(game_words)}"
        
        return f"Pas s√ªr des dates. Essaye `!gameinfo{game_hint}` üòâ"
    
    return None


def filter_generic_responses(response: str) -> str:
    """Filter out generic/cringe AI phrases and make responses punchier."""
    # Liste de phrases g√©n√©riques √† √©viter (auto-congratulation)
    generic_phrases = [
        "je vais devoir ajouter",
        "ma liste de qualit√©s",
        "ma longue liste",
        "quelqu'un doit bien le faire",
        "c'est mon travail",
        "je suis l√† pour",
        "mes capacit√©s incroyables",
        "fantastique",
    ]
    
    # Si la r√©ponse contient des phrases g√©n√©riques, on la rejette (retourne vide)
    response_lower = response.lower()
    for phrase in generic_phrases:
        if phrase in response_lower:
            return ""  # Force un retry ou fallback
    
    return response


async def handle_chill_command(message: Message, config: dict, now, conversation_manager=None, llm_available: bool = True, bot=None, translator=None):  # pylint: disable=unused-argument
    """Commande !chill - R√©pond en mode conversationnel.
    
    Args:
        message: Message Twitch
        config: Configuration du bot
        now: Timestamp actuel
        conversation_manager: Gestionnaire de conversation (optionnel)
        llm_available: Si le LLM est disponible (d√©faut: True pour r√©trocompatibilit√©)
        bot: Instance du bot (pour safe_send avec badge)
        translator: Instance du Translator (pour filtre artefacts multilingues)
    """
    botname = config["bot"]["name"].lower()
    debug = config["bot"].get("debug", False)
    user_name = str(message.author.name or "user").lower()
    
    # Helper pour envoyer avec ou sans badge
    async def send(msg):
        if bot:
            await bot.safe_send(message.channel, msg)
        else:
            await message.channel.send(msg)

    # Extraire le contenu du message
    raw_content = message.content or ""
    
    # V√©rifier si le bot est mentionn√© (KISS: chercher botname n'importe o√π avec espaces)
    content_lower = f" {raw_content.lower()} "
    has_mention = f" {botname} " in content_lower or f"@{botname}" in content_lower
    
    # Si pas de mention du bot, ignorer le message
    if not has_mention:
        if debug:
            print(f"[CHILL] ‚è≠Ô∏è  Pas de mention du bot dans: '{raw_content[:40]}...'")
        return
    
    # Nettoyer le message: retirer @ et le nom du bot
    content = raw_content.replace("@", "").strip()
    content_lower = content.lower()
    
    # Retirer le botname du contenu
    words = content_lower.split()
    
    # Si le botname est le seul mot, remplacer par "Salut !"
    if len(words) == 1 and words[0] == botname:
        content = "Salut !"
    # Sinon retirer le botname en d√©but ou fin de phrase
    else:
        # Retirer en d√©but
        if content_lower.startswith(botname + " "):
            content = content[len(botname):].strip()
        # Retirer en fin
        elif content_lower.endswith(" " + botname):
            content = content[:-len(botname)].strip()
        else:
            # Si au milieu, le laisser (ex: "comment va serda_bot ?")
            content = content.strip()
    
    if not content:
        content = "Salut !"

    # R√©cup√©rer game/title depuis config (si disponible)
    game = config.get("stream", {}).get("game")
    title = config.get("stream", {}).get("title")

    # === MODE CHILL: PAS DE ROUTING ===
    # En mode CHILL (conversation casual), on va TOUJOURS au LLM direct
    # Le routing est r√©serv√© au mode ASK (!ask) pour les questions factuelles
    if debug:
        print("[CHILL] üí¨ Mode conversation ‚Üí LLM direct (pas de routing)")
    
    # === V√©rifier disponibilit√© LLM ===
    if not llm_available:
        if debug:
            print(f"[CHILL] ü§ñ LLM non disponible ‚Üí mode fallback")
        
        fallback_msg = get_fallback_response("chill")
        
        try:
            await send(fallback_msg)
            if debug:
                print(f"[CHILL] ‚úÖ Fallback envoy√©: {fallback_msg}")
        except Exception as e:
            print(f"[SEND] ‚ùå Erreur envoi fallback: {e}")
        return
    
    # === CONTEXTE CONVERSATIONNEL ===
    # R√©cup√©rer l'historique des 3 derniers messages de cet utilisateur
    conversation_history = []
    if conversation_manager:
        state = conversation_manager.get(user_name)
        with state.lock:
            # Garder les 3 derniers messages (user + assistant)
            conversation_history = state.messages[-6:] if len(state.messages) > 0 else []
            if debug and conversation_history:
                print(f"[CONTEXT] üí¨ {len(conversation_history)} messages d'historique pour {user_name}")
    
    # === LOGIQUE NORMALE (pas de trigger proactif) ===
    # Construire le prompt avec make_prompt + contexte
    if conversation_history:
        # Construire un contexte texte pour le prompt
        context_text = "\n".join([f"{msg['role']}: {msg['content']}" for msg in conversation_history])
        prompt = make_prompt(mode="chill", content=f"[Contexte conversation]\n{context_text}\n\n[Message actuel]\n{content}", user=user_name, game=game, title=title)
    else:
        prompt = make_prompt(mode="chill", content=content, user=user_name, game=game, title=title)

    if debug:
        print(f"[LLM] üìù Prompt: user={user_name} | content='{content[:40]}...' | size={len(prompt)} chars | historique={len(conversation_history)} msg")

    llm_start = time.time()
    response = await call_model(prompt, config, user=user_name, mode="chill")
    llm_time = (time.time() - llm_start) * 1000  # ms

    if debug:
        print(f"[LLM] üì® R√©ponse: size={len(response) if response else 0} chars | latence={llm_time:.0f}ms | preview='{response[:60] if response else 'VIDE'}...'")

    # === FILTRE ARTEFACTS MULTILINGUES ===
    has_artifact = False
    chinese_word = ""
    translation = ""
    if response and translator:
        response, has_artifact, chinese_word, translation = detect_and_translate_artifacts(response, translator, debug)

    # === SAUVEGARDER DANS L'HISTORIQUE ===",
    if conversation_manager and response:
        conversation_manager.add_message(user_name, "user", content)
        conversation_manager.add_message(user_name, "assistant", response)
        if debug:
            print(f"[CONTEXT] üíæ Messages sauvegard√©s pour {user_name}")

    # Si tous les LLM ont √©chou√© (LM Studio + OpenAI) ‚Üí fallback r√©pliques
    if response is None:
        if debug:
            print(f"[CHILL] ü§ñ Tous LLM indisponibles ‚Üí fallback r√©pliques")
        fallback_msg = get_fallback_response("chill")
        try:
            await send(f"@{user_name} {fallback_msg}")
            if debug:
                print(f"[CHILL] ‚úÖ Fallback error envoy√©: {fallback_msg}")
        except Exception as e:
            print(f"[SEND] ‚ùå Erreur envoi fallback: {e}")
        return
    
    if not response:
        await send("ü§∑ R√©ponse manquante.")
        return

    # Post-filter: d√©tection r√©ponses vagues sur les jeux
    filter_start = time.time()
    vague_redirect = detect_vague_game_response(content, response)
    filter_time = (time.time() - filter_start) * 1000  # ms
    
    if vague_redirect:
        if debug:
            # Extraire game hint du message de redirection
            hint_match = re.search(r'!gameinfo\s*(\w+)?', vague_redirect)
            game_hint = hint_match.group(1) if hint_match and hint_match.group(1) else "(vide)"
            print(f"[POST-FILTER] üõ°Ô∏è  BLOQU√â: user='{content[:40]}' | llm='{response[:40]}...' | hint={game_hint} | latence={filter_time:.1f}ms")
        final_response = vague_redirect
    else:
        if debug:
            print(f"[POST-FILTER] ‚úÖ OK: pas de d√©tection ({filter_time:.1f}ms)")
        # Filtre anti-g√©n√©rique (garde la spontan√©it√© du bot)
        filtered = filter_generic_responses(response.strip())
        if not filtered:
            if debug:
                print(f"[CHILL] ‚ö†Ô∏è R√©ponse g√©n√©rique filtr√©e: {response[:50]}...")
            filtered = "ü§î Hmm, laisse-moi r√©fl√©chir √† √ßa..."

        # S√©curit√© Twitch (rare mais filet de s√©curit√©)
        final_response = filtered if len(filtered) <= 500 else filtered[:497] + "‚Ä¶"
    
    try:
        send_start = time.time()
        await send(final_response)
        send_time = (time.time() - send_start) * 1000  # ms
        
        if debug:
            total_time = (llm_time if 'llm_time' in locals() else 0) + (filter_time if 'filter_time' in locals() else 0) + send_time
            print(f"[SEND] ‚úÖ Envoy√©: @{user_name} | size={len(final_response)} chars | latence={send_time:.0f}ms")
            print(f"[METRICS] ‚è±Ô∏è  Total: {total_time:.0f}ms (llm={llm_time if 'llm_time' in locals() else 0:.0f} + filter={filter_time if 'filter_time' in locals() else 0:.0f} + send={send_time:.0f})")
        
        # === EASTER EGG: F√âLICITATION RETARD√âE SI ARTEFACT CHINOIS ===
        if has_artifact and chinese_word and translation:
            if debug:
                print(f"[ARTIFACT] ‚è≥ Attente 3s avant f√©licitation...")
            
            await asyncio.sleep(3)  # Suspense de 3 secondes
            
            congrats_msg = f"üéì @{user_name} Wow ! Tu viens d'unlock un easter egg chinois : {chinese_word} = {translation} !"
            try:
                await send(congrats_msg)
                if debug:
                    print(f"[ARTIFACT] üéâ F√©licitation envoy√©e: {congrats_msg}")
            except Exception as e:
                print(f"[SEND] ‚ùå Erreur envoi f√©licitation: {e}")
    except Exception as e:
        print(f"[SEND] ‚ùå Erreur: {e}")
