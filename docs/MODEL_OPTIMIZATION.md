# ğŸ”¬ Optimisation ModÃ¨le - RÃ©sultats Tests Scientifiques

> Documentation des tests comparatifs entre Qwen2.5-1.5B et Qwen2.5-7B

## ğŸ“Š RÃ©sumÃ© ExÃ©cutif

**ModÃ¨le retenu** : Qwen2.5-1.5B-Instruct-Q4_K_M  
**Raison** : FiabilitÃ© supÃ©rieure (98.9% vs 94.4%), plus concis, moins de ressources

---

## ğŸ§ª Tests EffectuÃ©s

### Test 1 : max_tokens (30-80)
- **Objectif** : Trouver la limite optimale pour phrases complÃ¨tes
- **MÃ©thode** : Question identique testÃ©e avec diffÃ©rentes limites
- **RÃ©sultat** : 
  - 1.5B : 100% complet dÃ¨s 40 tokens avec prompt "RÃ©ponds en une phrase"
  - 7B : NÃ©cessite 70-80 tokens, plus verbeux

### Test 2 : TempÃ©ratures (0.0-1.0)
- **Objectif** : Impact de la tempÃ©rature sur qualitÃ©/crÃ©ativitÃ©
- **MÃ©thode** : 15 questions Ã— 6 tempÃ©ratures (90 tests totaux)
- **Dataset** : Animaux, tech, science, histoire, gaming, divers

#### RÃ©sultats Qwen2.5-1.5B
```
Tests total: 90
Longueur moyenne: 97.6 chars
Range: 15-180 chars
Taux phrases complÃ¨tes: 98.9% (89/90)

Par tempÃ©rature:
  T=0.0: 102 chars, 100% âœ…
  T=0.2:  97 chars,  93%
  T=0.4:  98 chars, 100% âœ… â† OPTIMAL
  T=0.6: 104 chars, 100% âœ…
  T=0.8:  98 chars, 100% âœ…
  T=1.0:  87 chars, 100% âœ…
```

#### RÃ©sultats Qwen2.5-7B
```
Tests total: 90
Longueur moyenne: 120.8 chars (+24% vs 1.5B)
Range: 41-247 chars
Taux phrases complÃ¨tes: 94.4% (85/90)

Par tempÃ©rature:
  T=0.0: 130 chars, 100% âœ…
  T=0.2: 131 chars, 100% âœ…
  T=0.4: 122 chars,  93%
  T=0.6: 118 chars,  93%
  T=0.8: 102 chars,  87% âŒ (glitchs chinois)
  T=1.0: 122 chars,  93%
```

### Test 3 : Avec/Sans Exemples Few-Shot
- **Avec exemples** : 1.5B copie exactement (perroquet)
- **Sans exemples** : 1.5B varie naturellement, reste fiable Ã  98.9%
- **Conclusion** : Exemples inutiles, le modÃ¨le est performant sans

---

## ğŸ¯ Configuration Finale Optimale

### Mode ASK (Questions factuelles)
```python
MAX_TOKENS_ASK = 80     # Permet finir phrases proprement
TEMP_ASK = 0.4          # Sweet spot: 98 chars moyens, 100% fiable
```

**Prompt** :
```
RÃ©ponds en une phrase. Maximum 230 caractÃ¨res. 
Si tu ne sais pas, dis "Je ne sais pas".
```

**Transformation question** :
```python
# Force le modÃ¨le Ã  finir en ajoutant contrainte dans USER prompt
"parle moi des pandas roux" â†’ "parle moi des pandas roux ? RÃ©ponds en une phrase."
"python" â†’ "C'est quoi python ? RÃ©ponds en une phrase."
```

### Mode CHILL (Interactions sociales)
```python
MAX_TOKENS_CHILL = 45   # Adapte naturellement 1-2 phrases
TEMP_CHILL = 0.5        # LÃ©gÃ¨rement plus crÃ©atif
```

**Prompt** :
```
Tu es serda_bot, bot Twitch cool et dÃ©contractÃ©.
Adapte ta rÃ©ponse : 1-5 mots pour rÃ©actions simples, 
jusqu'Ã  2 phrases courtes si question intÃ©ressante.
TERMINE TOUJOURS tes phrases.
```

---

## âš ï¸ ProblÃ¨mes IdentifiÃ©s

### Hallucinations (1.5B)
Le modÃ¨le invente des faits incorrects :
- "pandas roux = louveteaux bearacÃ©es"
- "trou noir = jeu vidÃ©o Ubisoft 1998"
- "axolotl = poisson amphibien" (c'est une salamandre)

**Solution prÃ©vue** : Fact Cache (Wikipedia/Wikidata) pour questions factuelles courantes

### Glitchs Multilingues (7B)
Ã€ Tâ‰¥0.8, le 7B bascule en chinois alÃ©atoirement :
- "blockchain" â†’ Mix franÃ§ais/chinois
- "react" â†’ "React est un framework JavaScriptç”¨äºæ„å»ºç”¨æˆ·ç•Œé¢"
- "trou noir" â†’ RÃ©ponse complÃ¨te en chinois

**Raison** : ModÃ¨le multilingue instable Ã  haute tempÃ©rature  
**Solution** : Utiliser le 1.5B qui n'a pas ce problÃ¨me

---

## ğŸ“ˆ MÃ©triques de Performance

| MÃ©trique | 1.5B | 7B | Gagnant |
|----------|------|-----|---------|
| **FiabilitÃ©** | 98.9% | 94.4% | ğŸ† 1.5B |
| **Concision** | 97.6 chars | 120.8 chars | ğŸ† 1.5B |
| **StabilitÃ© temp** | 100% Ã  T=0.4-1.0 | 87% Ã  T=0.8 | ğŸ† 1.5B |
| **QualitÃ© factuelle** | â­â­â­ | â­â­â­â­ | 7B |
| **RAM/CPU** | ~1.5 GB | ~5 GB | ğŸ† 1.5B |
| **Vitesse** | ~70 tok/s | ~80 tok/s | 7B |

**Score final** : 1.5B domine sur fiabilitÃ©, ressources et stabilitÃ©

---

## ğŸš€ Prochaines Ã‰tapes

### 1. Fact Cache (PrioritÃ© Haute)
ImplÃ©menter cache Wikipedia/Wikidata pour corriger hallucinations sur :
- Animaux (pandas roux, axolotl, etc.)
- Technologie (Python, blockchain, etc.)
- Science (trou noir, ADN, etc.)
- Gaming (Minecraft, Valorant, etc.)

**APIs potentielles** :
- Wikipedia API (fr.wikipedia.org/api)
- Wikidata SPARQL
- DBpedia (fallback)

### 2. Monitoring Production
Logger les mÃ©triques :
- Longueur rÃ©ponses
- finish_reason (stop vs length)
- Taux phrases incomplÃ¨tes
- Hallucinations dÃ©tectÃ©es (via fact_cache)

### 3. Fine-tuning (Long terme)
Si hallucinations persistent :
- Dataset curated franÃ§ais
- LoRA fine-tune sur connaissances factuelles
- Validation humaine

---

## ğŸ“ Changelog

**2025-10-18** : Tests scientifiques initiaux
- Comparaison 1.5B vs 7B (90 tests)
- Optimisation max_tokens et tempÃ©rature
- DÃ©cision : 1.5B en production
- Config : MAX_TOKENS_ASK=80, TEMP_ASK=0.4

---

## ğŸ”— Scripts de Test

- `scripts/test_max_tokens.py` : Test limites tokens
- `scripts/compare_1_5b_vs_7b.py` : Comparaison cÃ´te Ã  cÃ´te
- `scripts/compare_temperatures.py` : Analyse tempÃ©ratures (90 tests)

**Relancer les tests** :
```bash
source venv/bin/activate
python scripts/compare_temperatures.py
```
