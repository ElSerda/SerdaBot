# Fact Cache - Plan d'Impl√©mentation

## üéØ Objectif
Corriger les hallucinations du 1.5B en fournissant des faits v√©rifi√©s depuis des sources fiables (Wikipedia, Wikidata).

---

## üìã TODO

### Phase 1 : Infrastructure de Base
- [ ] Cr√©er `src/utils/fact_cache.py`
- [ ] Impl√©menter cache local JSON pour √©viter trop d'API calls
- [ ] D√©finir structure cache : `{"query": str, "facts": str, "source": str, "timestamp": int}`
- [ ] TTL cache : 30 jours (facts changent peu)

### Phase 2 : Int√©gration Wikipedia
- [ ] API wrapper Wikipedia FR : `https://fr.wikipedia.org/api/rest_v1/page/summary/{title}`
- [ ] Extraire `extract` (r√©sum√© 200-300 chars)
- [ ] Normaliser query ‚Üí Wikipedia title (fuzzy match)
- [ ] Fallback English si FR vide

### Phase 3 : Int√©gration Wikidata (Optionnel)
- [ ] SPARQL queries pour faits structur√©s
- [ ] Mapping entit√©s ‚Üí propri√©t√©s cl√©s
- [ ] Exemple : "panda roux" ‚Üí P31 (instance of), P141 (conservation status)

### Phase 4 : D√©tection Besoin Cache
- [ ] Analyser query : d√©tection entit√©s nomm√©es
- [ ] Cat√©gories prioritaires : animaux, tech, science, histoire
- [ ] Si match ‚Üí inject fact dans system prompt ou remplace r√©ponse

### Phase 5 : Mode Hybride
**Option A** : Inject fact dans prompt
```
SYSTEM: "Fait v√©rifi√©: Les pandas roux sont des mammif√®res..."
USER: "parle moi des pandas roux"
```

**Option B** : Remplace r√©ponse si match exact
```python
if fact_cache.has("pandas roux"):
    return fact_cache.get("pandas roux")
else:
    return model_response
```

**Option C** : Enrichissement post-g√©n√©ration
```python
response = model.generate()
facts = fact_cache.check(response)
if facts.hallucination_detected:
    return facts.verified_version
```

### Phase 6 : Testing
- [ ] Test unitaires cache
- [ ] Test int√©gration Wikipedia API
- [ ] Benchmark : latency impact (< 100ms acceptable)
- [ ] Validation qualit√© : 10 queries test

---

## üõ†Ô∏è APIs Candidates

### Wikipedia REST API
```bash
curl https://fr.wikipedia.org/api/rest_v1/page/summary/Petit_panda
```
**Pros** : Simple, rapide, r√©sum√©s parfaits  
**Cons** : N√©cessite titre exact

### Wikidata SPARQL
```sparql
SELECT ?item ?itemLabel ?desc WHERE {
  ?item rdfs:label "panda roux"@fr.
  ?item schema:description ?desc.
  FILTER(LANG(?desc) = "fr")
}
```
**Pros** : Donn√©es structur√©es, multilingue  
**Cons** : Plus complexe, requ√™tes plus lentes

### DBpedia (Fallback)
**Pros** : RDF, compatible SPARQL  
**Cons** : Donn√©es parfois obsol√®tes

---

## üì¶ Structure Code Pr√©vue

```
src/utils/fact_cache.py
‚îú‚îÄ‚îÄ FactCache (class)
‚îÇ   ‚îú‚îÄ‚îÄ __init__(cache_file: str, ttl: int)
‚îÇ   ‚îú‚îÄ‚îÄ get(query: str) -> Optional[str]
‚îÇ   ‚îú‚îÄ‚îÄ set(query: str, facts: str, source: str)
‚îÇ   ‚îú‚îÄ‚îÄ has(query: str) -> bool
‚îÇ   ‚îî‚îÄ‚îÄ cleanup_expired()
‚îÇ
‚îú‚îÄ‚îÄ WikipediaClient (class)
‚îÇ   ‚îú‚îÄ‚îÄ search(query: str) -> Optional[str]
‚îÇ   ‚îú‚îÄ‚îÄ get_summary(title: str) -> str
‚îÇ   ‚îî‚îÄ‚îÄ normalize_title(query: str) -> str
‚îÇ
‚îî‚îÄ‚îÄ inject_facts(prompt: str, query: str, cache: FactCache) -> str
```

**Usage** :
```python
from src.utils.fact_cache import FactCache, inject_facts

cache = FactCache("data/fact_cache.json", ttl=30*24*3600)

# Dans ask_command.py
prompt = "parle moi des pandas roux"
enriched_prompt = inject_facts(prompt, query=prompt, cache=cache)
# ‚Üí Ajoute fact Wikipedia dans system prompt si trouv√©
```

---

## ‚ö†Ô∏è Consid√©rations

### Latency
- Cache hit : ~1ms
- Cache miss + Wikipedia API : ~200-500ms
- **Solution** : Async pre-fetch queries fr√©quentes

### Fra√Æcheur Donn√©es
- Wikipedia change peu (TTL 30j OK)
- Sujets tech : peut √™tre obsol√®te (Python versions, etc.)
- **Solution** : TTL adaptatif par cat√©gorie

### Privacy
- Pas de donn√©es user logg√©es
- Queries fact_cache anonymes
- OK RGPD

### Co√ªt
- Wikipedia API : Gratuit, rate limit 200 req/s
- Wikidata SPARQL : Gratuit, rate limit 60 req/s
- **Solution** : Respecter rate limits, cache agressif

---

## üéØ Crit√®res de Succ√®s

1. **R√©duction hallucinations** : -80% sur animaux/tech/science
2. **Latency acceptable** : <200ms P95 avec cache
3. **Hit rate** : >70% sur queries ASK fr√©quentes
4. **Qualit√©** : Validation humaine 10 queries ‚Üí 9/10 correctes

---

## üìÖ Timeline Estim√©

- **Semaine 1** : Infrastructure + cache local
- **Semaine 2** : Wikipedia API + tests
- **Semaine 3** : Int√©gration ask_command + monitoring
- **Semaine 4** : Optimisation + pre-fetch queries populaires

**Total** : ~1 mois pour fact_cache robuste

---

## üîó Ressources

- [Wikipedia API Docs](https://www.mediawiki.org/wiki/API:Main_page)
- [Wikidata SPARQL](https://query.wikidata.org/)
- [DBpedia Lookup](https://lookup.dbpedia.org/)
