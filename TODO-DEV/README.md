# ‚úÖ TODO-DEV : Fichiers Cr√©√©s et Actions Compl√©t√©es

> **Date :** 20 octobre 2025  
> **Contexte :** Suite analyse architecturale SerdaBot (score 9.2/10)

---

## üìÇ Fichiers Cr√©√©s

### 1. `OPTIMISATIONS.md`
**Contenu :** TODO structur√© avec 6 t√¢ches prioritis√©es
- üî¥ Haute : Centralisation cooldowns, Heartbeat, Structured output
- üü° Moyenne : Cache LLM, M√©triques export
- üü¢ Basse : Documentation architecture

**Prochaines actions :**
1. Impl√©menter `RateLimiter` centralis√© (4h)
2. Choisir strat√©gie heartbeat vs retry (voir HEARTBEAT_VS_RETRY.md)

---

### 2. `BENCHMARK_RAM_COOLDOWNS.md`
**Contenu :** Plan de benchmark RAM pour cooldowns par user

**R√©sultats obtenus :**
```
| Users  | Simple (MB) | Hourly (MB) | Full (MB) | Total |
|--------|-------------|-------------|-----------|-------|
|    100 |        0.01 |        0.08 |      0.06 |  0.15 |
|  1,000 |        0.11 |        0.76 |      0.59 |  1.47 |
| 10,000 |        1.09 |        7.64 |      5.90 | 14.63 |
```

**‚úÖ Conclusion : Impact RAM N√âGLIGEABLE (5.9 MB pour 10K users)**

**Prochaine action :** Impl√©menter cooldown par user sans h√©sitation

---

### 3. `HEARTBEAT_VS_RETRY.md`
**Contenu :** Analyse comparative d√©taill√©e

**Recommandation finale :**
- **Phase 1 (MAINTENANT)** : Retry intelligent avec backoff exponentiel
  - Simple (50 lignes)
  - Suffisant pour dev/test
  - 30-60 min impl√©mentation

- **Phase 2 (PROD 24/7)** : Heartbeat proactif
  - D√©tection proactive
  - M√©triques uptime
  - Justifi√© en production

**Prochaine action :** Impl√©menter retry intelligent cette semaine

---

### 4. `scripts/benchmark_cooldowns_ram.py`
**Contenu :** Script benchmark fonctionnel

**Features :**
- ‚úÖ Fonctionne avec ou sans `memory_profiler`
- ‚úÖ Tests 100 / 1K / 10K users
- ‚úÖ Option `--extreme` pour 50K users
- ‚úÖ Mesure RAM + temps cleanup + temps lookup

**Utilisation :**
```bash
cd TODO-DEV/scripts
python benchmark_cooldowns_ram.py
# OU avec profiler d√©taill√©
pip install memory-profiler psutil
python -m memory_profiler benchmark_cooldowns_ram.py
```

---

## ‚öôÔ∏è Configuration Mise √† Jour

### `config.yaml` - Nouvelle section `rate_limiting`

**Ajout√© :**
```yaml
rate_limiting:
  # User cooldowns (bas√© sur model_limits.json)
  user_cooldown: 10                    # Actuel
  max_requests_per_user_hour: 20       # Nouveau
  max_concurrent_users: 7              # model_limits.json
  
  # Cleanup (bas√© sur benchmark RAM)
  cleanup_interval: 600                # 10min
  max_idle_time: 3600                  # 1h
  
  # LLM retry intelligent (Phase 1)
  llm_retry_delay: 5                   # 5s ‚Üí 10s ‚Üí 20s ‚Üí ...
  llm_backoff_multiplier: 2
  llm_backoff_max: 300                 # Max 5min
  
  # Heartbeat (Phase 2 - d√©sactiv√©)
  health_check_enabled: false
  health_check_interval: 30
  
  # External APIs
  wikipedia_rate_limit: 1.0
  igdb_rate_limit: 4.0

# Performance (auto-tuned)
max_concurrent_users_modere: 7         # Production recommand√©
```

**Sources :**
- `config/model_limits.json` : max_concurrent_users_modere = 7
- Benchmark RAM : 5.9 MB pour 10K users (n√©gligeable)
- auto-tune/ : user_rate_limit = 0.5 req/sec

---

## üìä M√©triques de R√©f√©rence

### RAM (benchmark r√©el)
| Sc√©nario | RAM Full RateLimiter | Verdict |
|----------|---------------------|---------|
| 100 users (stream moyen) | 0.06 MB | ‚úÖ N√©gligeable |
| 1K users (gros stream) | 0.59 MB | ‚úÖ N√©gligeable |
| 10K users (viral) | 5.90 MB | ‚úÖ Acceptable |

### Performance LLM (model_limits.json)
| Mode | Max Users | Latence Max | Throughput |
|------|-----------|-------------|------------|
| Brut | 4 | 2.41s | N/A |
| Mod√©r√© | 7 | 2.49s | ~22-60 tok/s |

---

## üéØ Prochaines Actions Prioritaires

### Cette semaine (üî¥ Haute priorit√©)

1. **Impl√©menter Retry Intelligent**
   - Cr√©er `src/utils/endpoint_tracker.py`
   - Modifier `src/utils/model_utils.py`
   - Tester avec `scripts/test_endpoint_fallback.py` (√† cr√©er)
   - **Temps estim√© :** 30-60 min

2. **Centraliser Cooldowns**
   - Cr√©er `src/utils/rate_limiter.py`
   - Migrer cooldowns de `twitch_bot.py`
   - Migrer `_failed_endpoints` de `model_utils.py`
   - Migrer `_last_wiki_call` de `cache_manager.py`
   - **Temps estim√© :** 3-4 heures

3. **Lancer Benchmark Extr√™me (optionnel)**
   ```bash
   python TODO-DEV/scripts/benchmark_cooldowns_ram.py --extreme
   ```
   - Mesurer 50K users
   - Valider conclusions

### Ce mois (üü° Moyenne priorit√©)

4. **Activer Structured Output (metadata)**
   - Modifier `chill_command.py` : `extract_metadata=True`
   - Ajouter √©mojis contextuels selon tone
   - Ajouter disclaimer si confidence < 0.6
   - **Temps estim√© :** 2 heures

5. **Cache LLM Responses (optionnel)**
   - Cr√©er `src/utils/llm_cache.py`
   - Int√©grer dans `call_model()`
   - **Temps estim√© :** 3 heures

### Quand temps disponible (üü¢ Basse priorit√©)

6. **Documentation Architecture**
   - Diagrammes s√©quence (pipeline flow)
   - ADR (Architecture Decision Records)
   - **Temps estim√© :** 4 heures

7. **Migrer vers Heartbeat (prod 24/7)**
   - Cr√©er `src/utils/health_monitor.py`
   - Int√©grer dans `twitch_bot.py` au boot
   - **Temps estim√© :** 2-3 heures

---

## üìù Notes Importantes

### Pourquoi ces priorit√©s ?

**Retry Intelligent (Phase 1) :**
- ‚úÖ Simple √† impl√©menter (30 min)
- ‚úÖ Am√©lioration imm√©diate (vs cache fixe 2min)
- ‚úÖ Pas de complexit√© additionnelle
- ‚úÖ Compatible avec Phase 2 future

**Cooldowns centralis√©s :**
- ‚úÖ Benchmark prouve RAM n√©gligeable (5.9 MB pour 10K users)
- ‚úÖ Code actuellement dispers√© (3 fichiers)
- ‚úÖ Facilite maintenance future
- ‚úÖ Pr√©pare rate limiting par user

**Heartbeat (Phase 2) :**
- ‚ö†Ô∏è Complexit√© additionnelle (+150 lignes)
- ‚ö†Ô∏è Justifi√© SEULEMENT en prod 24/7
- ‚ö†Ô∏è Attendre stabilit√© Phase 1

---

## üéì R√©f√©rences

### Fichiers √† lire
- `config/model_limits.json` : R√©sultats auto-tune
- `auto-tune/find_max_concurrent.py` : Script tuning
- `src/utils/model_utils.py` : Logique actuelle fallback
- `src/chat/twitch_bot.py` : Cooldowns actuels

### Commandes utiles
```bash
# Benchmark RAM
cd TODO-DEV/scripts && python benchmark_cooldowns_ram.py

# Auto-tune (si besoin re-tester)
cd auto-tune && python find_max_concurrent.py

# Tests int√©gration
cd scripts && python test_full_pipeline.py
cd scripts && python test_all_commands.py
```

---

## ‚úÖ Checklist Validation

**Avant impl√©mentation :**
- [x] Benchmark RAM lanc√© (r√©sultats : 5.9 MB pour 10K users)
- [x] Config `rate_limiting` ajout√©e dans `config.yaml`
- [x] Plan heartbeat vs retry analys√©
- [ ] Tests actuels passent (24/24 pipeline, 17/17 commands)

**Apr√®s impl√©mentation Retry Intelligent :**
- [ ] `src/utils/endpoint_tracker.py` cr√©√©
- [ ] `src/utils/model_utils.py` modifi√©
- [ ] Tests passent sans r√©gression
- [ ] Backoff valid√© (5s ‚Üí 10s ‚Üí 20s)

**Apr√®s impl√©mentation RateLimiter :**
- [ ] `src/utils/rate_limiter.py` cr√©√©
- [ ] Migrations termin√©es (3 fichiers)
- [ ] Config YAML utilis√©e (pas de hardcode)
- [ ] Tests 100% passing

---

## üöÄ R√©sum√© Ex√©cutif

**Ce qui a √©t√© fait :**
1. ‚úÖ Analyse architecturale compl√®te (score 9.2/10)
2. ‚úÖ Benchmark RAM cooldowns (n√©gligeable m√™me 10K users)
3. ‚úÖ Analyse heartbeat vs retry (recommandation Phase 1/2)
4. ‚úÖ Config enrichie avec `rate_limiting` (bas√© sur auto-tune)
5. ‚úÖ TODO structur√© avec priorit√©s claires

**Ce qui reste √† faire :**
1. üî¥ Impl√©menter retry intelligent (30-60 min)
2. üî¥ Centraliser cooldowns (3-4h)
3. üü° Activer structured output (2h)
4. üü° Cache LLM optionnel (3h)
5. üü¢ Documentation + Heartbeat Phase 2 (quand prod 24/7)

**Impact attendu :**
- Meilleure gestion fallback (retry intelligent)
- Code plus maintenable (cooldowns centralis√©s)
- Anti-spam efficace (limite par user valid√©e)
- Production-ready √† 95% (manque heartbeat proactif)

---

**Prochaine √©tape sugg√©r√©e :** Impl√©menter retry intelligent (fichier `endpoint_tracker.py`) cette semaine.
