# ğŸ¯ Heartbeat vs Retry Intelligent : Analyse DÃ©taillÃ©e

> **Contexte :** Gestion fallback LM Studio (local) â†’ OpenAI (cloud)  
> **ProblÃ¨me actuel :** Cache Ã©chec 2min hardcodÃ©, pas de vÃ©rification proactive  
> **Date :** 20 octobre 2025

---

## ğŸ“Š Ã‰tat Actuel (model_utils.py)

### StratÃ©gie actuelle : Cache Ã©chec fixe
```python
# model_utils.py - Ligne 41-75
_failed_endpoints: dict[str, datetime] = {}
_CACHE_DURATION = timedelta(minutes=2)  # HardcodÃ©

async def call_model(...):
    # Tente endpoint local
    if api_url and api_url not in _failed_endpoints:
        result = await try_endpoint(api_url, ...)
        if result:
            return result
        # Ã‰CHEC : cache 2min
        _failed_endpoints[api_url] = now + timedelta(minutes=2)
    
    # Fallback OpenAI
    return await try_openai_fallback(...)
```

**ProblÃ¨mes :**
- âŒ Timing arbitraire (pourquoi 2min ?)
- âŒ Pas de distinction Ã©chec rÃ©seau vs Ã©chec modÃ¨le
- âŒ Aucune tentative de rÃ©cupÃ©ration proactive
- âŒ Si local revient aprÃ¨s 30s, attente 90s inutiles

---

## ğŸ†š Comparaison des Options

### Option A : Heartbeat pÃ©riodique

**Architecture :**
```python
# model_utils.py
class ModelHealthMonitor:
    def __init__(self):
        self.endpoints = {
            "http://localhost:1234": {
                "status": "unknown",  # healthy | degraded | down | unknown
                "last_check": None,
                "consecutive_failures": 0,
                "last_successful_call": None
            }
        }
        self.health_check_task = None
    
    async def start(self):
        """Lance le heartbeat background."""
        self.health_check_task = asyncio.create_task(self._health_check_loop())
    
    async def _health_check_loop(self):
        """VÃ©rifie santÃ© tous les 30s."""
        while True:
            for endpoint, info in self.endpoints.items():
                try:
                    # Ping lÃ©ger (GET /health ou HEAD /)
                    async with httpx.AsyncClient(timeout=2.0) as client:
                        response = await client.get(f"{endpoint}/health")
                        if response.status_code == 200:
                            info["status"] = "healthy"
                            info["consecutive_failures"] = 0
                        else:
                            info["status"] = "degraded"
                except:
                    info["consecutive_failures"] += 1
                    if info["consecutive_failures"] >= 3:
                        info["status"] = "down"
                
                info["last_check"] = datetime.now()
            
            await asyncio.sleep(30)  # Configurable
    
    def is_endpoint_healthy(self, endpoint: str) -> bool:
        """VÃ©rifie si endpoint est disponible."""
        status = self.endpoints.get(endpoint, {}).get("status", "unknown")
        return status in ["healthy", "unknown"]  # Optimiste si jamais testÃ©
```

**Avantages :**
- âœ… **DÃ©tection proactive** : Sait AVANT requÃªte user si local down
- âœ… **RÃ©cupÃ©ration rapide** : DÃ©tecte quand local revient (max 30s)
- âœ… **MÃ©triques uptime** : Historique de santÃ© endpoints
- âœ… **Switch intelligent** : Peut forcer OpenAI si local instable
- âœ… **Dashboard ready** : Statut temps rÃ©el pour monitoring

**InconvÃ©nients :**
- âš ï¸ **+1 task asyncio** : Background thread permanent
- âš ï¸ **Appels API toutes les 30s** : NÃ©gligeable (HEAD request, <10ms)
- âš ï¸ **ComplexitÃ©** : +100 lignes de code
- âš ï¸ **Faux positifs** : Ping OK mais modÃ¨le KO (rare)

**Configuration suggÃ©rÃ©e :**
```yaml
bot:
  health_check_enabled: true
  health_check_interval: 30     # Secondes entre pings
  health_check_timeout: 2       # Timeout du ping
  health_check_failures_threshold: 3  # Ã‰checs avant "down"
```

**Cas d'usage idÃ©al :**
- ğŸ¯ Production 24/7
- ğŸ¯ SLA strict (uptime > 99%)
- ğŸ¯ Monitoring dashboard (Grafana)
- ğŸ¯ Environnement instable (LM Studio crash frÃ©quents)

---

### Option B : Retry intelligent (Backoff exponentiel)

**Architecture :**
```python
# model_utils.py
class EndpointFailureTracker:
    def __init__(self):
        self.failures = {}  # {endpoint: FailureInfo}
    
    def record_failure(self, endpoint: str):
        """Enregistre un Ã©chec et calcule backoff."""
        if endpoint not in self.failures:
            self.failures[endpoint] = FailureInfo(count=0, first_failure=datetime.now())
        
        info = self.failures[endpoint]
        info.count += 1
        info.last_failure = datetime.now()
        
        # Backoff exponentiel : 5s â†’ 10s â†’ 20s â†’ 40s â†’ 80s â†’ 160s â†’ 300s (max)
        info.backoff_seconds = min(300, 5 * (2 ** info.count))
    
    def record_success(self, endpoint: str):
        """Reset compteur Ã©checs."""
        if endpoint in self.failures:
            del self.failures[endpoint]
    
    def can_retry(self, endpoint: str) -> bool:
        """VÃ©rifie si assez de temps Ã©coulÃ© pour retry."""
        if endpoint not in self.failures:
            return True
        
        info = self.failures[endpoint]
        elapsed = (datetime.now() - info.last_failure).total_seconds()
        return elapsed >= info.backoff_seconds

# Dans call_model()
async def call_model(...):
    if tracker.can_retry(api_url):
        result = await try_endpoint(api_url, ...)
        if result:
            tracker.record_success(api_url)  # Reset
            return result
        tracker.record_failure(api_url)  # IncrÃ©mente backoff
    
    # Fallback OpenAI
    return await try_openai_fallback(...)
```

**Avantages :**
- âœ… **SimplicitÃ©** : Pas de thread background
- âœ… **Adaptatif** : Backoff s'ajuste selon nombre d'Ã©checs
- âœ… **LÃ©ger** : <50 lignes de code
- âœ… **Ã‰conome ressources** : Pas d'appels pÃ©riodiques

**InconvÃ©nients :**
- âš ï¸ **RÃ©actif seulement** : DÃ©couvre panne sur erreur user
- âš ï¸ **DÃ©lai rÃ©cupÃ©ration** : Peut attendre 5min avant retry
- âš ï¸ **Pas de mÃ©triques** : Pas d'historique uptime
- âš ï¸ **Accumulation Ã©checs** : Plusieurs users peuvent Ã©chouer avant fallback

**Configuration suggÃ©rÃ©e :**
```yaml
rate_limiting:
  llm_retry_delay: 5            # Premier retry aprÃ¨s 5s
  llm_backoff_multiplier: 2     # Exponentiel (Ã—2 Ã  chaque Ã©chec)
  llm_backoff_max: 300          # Max 5min entre retries
  llm_reset_on_success: true    # Reset compteur si succÃ¨s
```

**Cas d'usage idÃ©al :**
- ğŸ¯ Dev / Test
- ğŸ¯ Environnement stable (LM Studio fiable)
- ğŸ¯ PrioritÃ© simplicitÃ©
- ğŸ¯ Pas besoin monitoring temps rÃ©el

---

## ğŸ¯ Recommandation Finale

### Pour ton cas (SerdaBot) :

**Contexte :**
- Dev actuel (tests) â†’ Prod future (stream 24/7)
- LM Studio local (qwen2.5-3b) + OpenAI fallback
- Tests montrent : 7 users concurrent max, latence < 3s

**ğŸ”´ Phase 1 (MAINTENANT - Dev/Test) : Option B (Retry intelligent)**

**Raisons :**
1. âœ… Simple Ã  implÃ©menter (30min)
2. âœ… Pas de complexitÃ© additionnelle
3. âœ… Suffisant pour tests/dev
4. âœ… Compatible avec Option A future

**ImplÃ©mentation :**
```python
# src/utils/endpoint_tracker.py (nouveau fichier)
class EndpointFailureTracker:
    # ... (code ci-dessus)

# Dans model_utils.py
from src.utils.endpoint_tracker import EndpointFailureTracker
_endpoint_tracker = EndpointFailureTracker()

async def call_model(...):
    if _endpoint_tracker.can_retry(api_url):
        # Try local
        ...
    # Fallback OpenAI
```

**ğŸŸ¢ Phase 2 (PROD 24/7) : Option A (Heartbeat)**

**Raisons :**
1. âœ… DÃ©tection proactive = meilleure UX
2. âœ… MÃ©triques uptime pour monitoring
3. âœ… RÃ©cupÃ©ration rapide si local revient
4. âœ… JustifiÃ© pour production

**Trigger migration :**
- Quand stream devient 24/7 rÃ©gulier
- Si LM Studio instable (>5% downtime)
- Besoin dashboard monitoring

---

## ğŸ“‹ Plan d'ImplÃ©mentation

### Ã‰tape 1 : Retry Intelligent (cette semaine)

**Fichiers Ã  crÃ©er :**
```
src/utils/endpoint_tracker.py  (nouveau)
```

**Fichiers Ã  modifier :**
```
src/utils/model_utils.py       (ligne 41-75, remplacer cache fixe)
src/config/config.yaml          (ajouter rate_limiting.llm_*)
```

**Tests :**
```bash
# Test 1 : Ã‰chec local â†’ fallback OpenAI
# Test 2 : Backoff exponentiel (5s â†’ 10s â†’ 20s)
# Test 3 : Reset sur succÃ¨s
python scripts/test_endpoint_fallback.py
```

**Estimation :** 30-60 min

---

### Ã‰tape 2 : Heartbeat (prod future)

**Fichiers Ã  crÃ©er :**
```
src/utils/health_monitor.py    (nouveau)
```

**Fichiers Ã  modifier :**
```
src/utils/model_utils.py       (intÃ©grer health_monitor)
src/chat/twitch_bot.py         (start health monitor au boot)
```

**Tests :**
```bash
# Test 1 : Heartbeat dÃ©tecte local down en 30s
# Test 2 : Heartbeat dÃ©tecte local recovery
# Test 3 : Metrics uptime
python scripts/test_health_monitor.py
```

**Estimation :** 2-3 heures

---

## ğŸ”§ Configuration Finale SuggÃ©rÃ©e

```yaml
# config.yaml
bot:
  # ModÃ¨le local
  model_endpoint: http://127.0.0.1:1234/v1/chat/completions
  model_timeout: 10
  
  # Fallback cloud
  model_type: "openai"
  openai_model: "gpt-4o-mini"

rate_limiting:
  # ===== PHASE 1 : Retry Intelligent (ACTUEL) =====
  llm_retry_delay: 5            # Premier retry aprÃ¨s 5s
  llm_backoff_multiplier: 2     # Exponentiel
  llm_backoff_max: 300          # Max 5min
  
  # ===== PHASE 2 : Heartbeat (PROD FUTURE) =====
  # health_check_enabled: false  # Activer en prod
  # health_check_interval: 30    # Secondes entre pings
  # health_check_timeout: 2      # Timeout ping
  # health_check_failures_threshold: 3  # Ã‰checs avant "down"
```

---

## ğŸ¯ TL;DR

| CritÃ¨re | Retry Intelligent | Heartbeat |
|---------|-------------------|-----------|
| **ComplexitÃ©** | ğŸŸ¢ Simple (50 lignes) | ğŸŸ¡ Moyen (150 lignes) |
| **DÃ©tection panne** | âš ï¸ RÃ©active (sur erreur) | âœ… Proactive (avant erreur) |
| **RÃ©cupÃ©ration** | âš ï¸ Lente (jusqu'Ã  5min) | âœ… Rapide (max 30s) |
| **Ressources** | âœ… Aucune overhead | âš ï¸ +1 task background |
| **MÃ©triques** | âŒ LimitÃ©es | âœ… Uptime complet |
| **Production ready** | ğŸŸ¡ OK pour dev/test | âœ… IdÃ©al pour prod 24/7 |

**Recommandation : ImplÃ©menter Retry maintenant, migrer vers Heartbeat en prod.**
